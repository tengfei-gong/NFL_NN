{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb7c426a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import os\n",
    "import time\n",
    "import unidecode\n",
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import math\n",
    "import operator\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "\n",
    "import requests\n",
    "from requests.structures import CaseInsensitiveDict\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f58e68f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adba330",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "from keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000c97f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21635722",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3c6f0cb",
   "metadata": {},
   "source": [
    "<h2> 1. Passing Data<h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ea3644",
   "metadata": {},
   "source": [
    "<h5> Load PBP Data - Passing / QB <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58365efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_PBP_Passing = pd.read_csv(\"Defense/passing_pbp_coverage_OPP_081022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58101f46",
   "metadata": {},
   "source": [
    "<h5> Grouping <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78eb642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = df_PBP_Passing.groupby(by=['team',\"gameId\", \"playerId\",\"playerName\", 'oppTeamId','nickName']).sum()\n",
    "\n",
    "group.reset_index(inplace=True)\n",
    "group = group[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName','FP_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "c5df8baf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab69127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9028d23a",
   "metadata": {},
   "source": [
    "<h3> Load Passing by RouteType <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8ee91b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "passingRouteType = pd.read_csv(\"Split/Passing_RouteType_2020_0817.csv\")\n",
    "#passingRouteType = pd.read_csv(\"Split/Passing_RouteType0817.csv\")\n",
    "passingRouteType['route'] = passingRouteType['route'].astype(int)\n",
    "routeTypes = np.unique(passingRouteType['route'])\n",
    "\n",
    "for i in routeTypes:\n",
    "    a = passingRouteType[passingRouteType['route'] == i][['playerName','FP/DB']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/DB' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'], how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dee3a19",
   "metadata": {},
   "source": [
    "<h3> Load Passing by DropType <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83c3d274",
   "metadata": {},
   "outputs": [],
   "source": [
    "passingDropType = pd.read_csv(\"Split/Passing_DropType_2020_0817.csv\")\n",
    "#passingDropType = pd.read_csv(\"Split/Passing_DropType0817.csv\")\n",
    "dropType = np.unique(passingDropType['DropType_descr'])\n",
    "\n",
    "for i in dropType:\n",
    "    a = passingDropType[passingDropType['DropType_descr'] == i][['playerName','FP/DB']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/DB' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fba013",
   "metadata": {},
   "source": [
    "<h3> Load Passing by CoverageType  <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d1fcbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "passingCoverageType = pd.read_csv(\"Split/Passing_CoverageType_2020_0817.csv\")\n",
    "#passingCoverageType = pd.read_csv(\"Split/Passing_CoverageType0817.csv\")\n",
    "coverageType = np.unique(passingCoverageType['CoverageType_descr'])\n",
    "\n",
    "for i in coverageType:\n",
    "    a = passingCoverageType[passingCoverageType['CoverageType_descr'] == i][['playerName','FP/DB']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/DB' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc16cb79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ac9e4124",
   "metadata": {},
   "source": [
    "<h3> Load Defense FP/play <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "42b2f7ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#passingRouteType_def = pd.read_csv(\"Split/Passing_RouteTyoe_def_0817.csv\")\n",
    "passingRouteType_def = pd.read_csv(\"Split/Passing_RouteTyoe_def_2020_0817.csv\")\n",
    "passingRouteType_def['route'] = passingRouteType_def['route'].astype(int)\n",
    "targetType = np.unique(passingRouteType_def['route'])\n",
    "\n",
    "\n",
    "for i in targetType:\n",
    "    a = passingRouteType_def[passingRouteType_def['route'] == i][['nickName','FP/DB']].reset_index(drop = True)\n",
    "    split = str(i) + \"_def\"\n",
    "    a = a.rename(columns={'FP/DB' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6200854",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#passingDropType_def = pd.read_csv(\"Split/Passing_DropType_def_0817.csv\")\n",
    "passingDropType_def = pd.read_csv(\"Split/Passing_DropType_def_2020_0817.csv\")\n",
    "dropType = np.unique(passingDropType_def['DropType_descr'])\n",
    "\n",
    "\n",
    "for i in dropType:\n",
    "    a = passingDropType_def[passingDropType_def['DropType_descr'] == i][['nickName','FP/DB']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/DB' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea800a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "passingCoverageType_def = pd.read_csv(\"Split/Passing_CoverageType_def_2020_0817.csv\")\n",
    "coverageType = np.unique(passingCoverageType_def['CoverageType_descr'])\n",
    "\n",
    "\n",
    "for i in coverageType:\n",
    "    a = passingCoverageType_def[passingCoverageType_def['CoverageType_descr'] == i][['nickName','FP/DB']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/DB' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6944ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "371840f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "passingCoverageType_def = pd.read_csv(\"Split/Passing_CoverageType_def_pooled_2020_0817.csv\")\n",
    "coverageType = np.unique(passingCoverageType_def['CoverageType_pooled'])\n",
    "\n",
    "\n",
    "for i in coverageType:\n",
    "    a = passingCoverageType_def[passingCoverageType_def['CoverageType_pooled'] == i][['nickName','FP/DB']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/DB' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "507ebe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with position\n",
    "roster = pd.read_csv(\"roster.csv\", index_col = False)\n",
    "\n",
    "group = pd.merge(group, roster[['playerId', 'positionCategory']], left_on = ['playerId'],  #2\n",
    "                          right_on=['playerId'], how = 'left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4d628a",
   "metadata": {},
   "source": [
    "<h3> Train Test Split <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "894f1373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e76313d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "groupSplit = group.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6ee41bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(groupSplit, test_size=0.2)\n",
    "\n",
    "trainNum = train.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "testNum = test.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "\n",
    "X_train = trainNum.drop(['FP_total'], axis = 1)\n",
    "y_train = trainNum['FP_total']\n",
    "X_test = testNum.drop(['FP_total'], axis = 1)\n",
    "y_test = testNum['FP_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "4b9f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization\n",
    "def normalize(raw_data):\n",
    "    return ( (raw_data - raw_data.min())/(raw_data.max()-raw_data.min()) )\n",
    "# Standardization\n",
    "def standardize(raw_data):\n",
    "    return ((raw_data - np.mean(raw_data, axis = 0)) / np.std(raw_data, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c3e9aaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in X_train.columns:\n",
    "    X_train[i] = standardize(X_train[i])\n",
    "    \n",
    "for i in X_test.columns:    \n",
    "    X_test[i] = standardize(X_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "5ec8f54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "eeef35d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to array for neural network\n",
    "X_train_array = np.asarray(X_train).astype('float32')\n",
    "X_test_array = np.asarray(X_test).astype('float32')\n",
    "\n",
    "y_train_array = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_array = np.asarray(y_test).astype('float32').reshape((-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "9ba6c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "comparison_dict ={'model':[],'params': [],'score': []}\n",
    "params={'hidden_layer_sizes': [(20,5), (25,10)], \n",
    "        'activation': [ 'logistic', 'tanh', 'relu'], \n",
    "        'solver': ['sgd', 'adam'], \n",
    "        'alpha': [2, 10, 20]} \n",
    "# 'alpha': np.logspace(2,20)\n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha )\n",
    "                model = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                      activation = activation, solver = solver, alpha = alpha, random_state = 1)\n",
    "                model.fit(X_train_array, y_train_array)\n",
    "\n",
    "                y_test_pred = model.predict(X_test_array)\n",
    "                MSE = mean_squared_error(y_test_pred , y_test_array)\n",
    "                \n",
    "                model_score = math.sqrt(MSE)\n",
    "                comparison_dict['model'].append('neural_network_classifier')\n",
    "                comparison_dict['params'].append(model_params)\n",
    "                comparison_dict['score'].append(model_score)\n",
    "                \n",
    "dfMLResults = pd.DataFrame({'Model': comparison_dict.get('model') ,\n",
    "              'Param': comparison_dict.get('params') ,\n",
    "              'Score': comparison_dict.get('score')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "18d0314f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Param</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>((25, 10), logistic, sgd, 2)</td>\n",
       "      <td>5.163751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>((20, 5), logistic, sgd, 2)</td>\n",
       "      <td>5.209543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>((25, 10), logistic, sgd, 10)</td>\n",
       "      <td>5.222547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>((20, 5), logistic, sgd, 10)</td>\n",
       "      <td>5.278690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>neural_network_classifier</td>\n",
       "      <td>((25, 10), relu, adam, 20)</td>\n",
       "      <td>5.284907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model                          Param     Score\n",
       "18  neural_network_classifier   ((25, 10), logistic, sgd, 2)  5.163751\n",
       "0   neural_network_classifier    ((20, 5), logistic, sgd, 2)  5.209543\n",
       "19  neural_network_classifier  ((25, 10), logistic, sgd, 10)  5.222547\n",
       "1   neural_network_classifier   ((20, 5), logistic, sgd, 10)  5.278690\n",
       "35  neural_network_classifier     ((25, 10), relu, adam, 20)  5.284907"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfMLResults.sort_values(by = ['Score']).head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "55ce4ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidates\n",
    "# ((25, 10), logistic, sgd, 2)\n",
    "# ((25, 10), relu, adam, 20)\n",
    "\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes = (25, 10),\n",
    "                                      activation = 'relu', solver = 'adam', alpha = 2, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4ab0e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['FP_total_pred'] = y_test_pred\n",
    "test_FP = test[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName',\n",
    "       'FP_total', 'FP_total_pred']].reset_index(drop = True)\n",
    "test_FP = test_FP.sort_values(by=['FP_total_pred'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "24411bcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_FP.to_csv(\"NN_Data/Pred/PassingPred_081122.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a521c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344bf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db9d3db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57458aac",
   "metadata": {},
   "source": [
    "<h2> 2. Receiving <h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6e95a9",
   "metadata": {},
   "source": [
    "<h5> Load Receiving <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "ae441ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "receiving = pd.read_csv(\"NN_Data/Defense/receiving_pbp_OPP_081022.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f9acf",
   "metadata": {},
   "source": [
    "<h5> Grouping <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "05b264a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = receiving.groupby(by=['team',\"gameId\", \"playerId\",\"playerName\", 'oppTeamId','nickName']).sum()\n",
    "\n",
    "group.reset_index(inplace=True)\n",
    "group = group[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName','FP_total']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad476d05",
   "metadata": {},
   "source": [
    "<h5> Load RouteType <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "id": "2fe5a580",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingRoute = pd.read_csv(\"Split/Receiving_RouteType_0817.csv\")\n",
    "receivingRoute = pd.read_csv(\"Split/Receiving_RouteType_2020_0817.csv\")\n",
    "receivingRoute['route'] = receivingRoute['route'].astype(int)\n",
    "targetType = np.unique(receivingRoute['route'])\n",
    "\n",
    "for i in targetType:\n",
    "    a = receivingRoute[receivingRoute['route'] == i][['playerName','FP/routes']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/routes' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'] , how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88b00e",
   "metadata": {},
   "source": [
    "<h5> Load DropType <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "id": "d57133ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingDrop = pd.read_csv(\"Split/Receiving_DropType_0817.csv\")\n",
    "receivingDrop = pd.read_csv(\"Split/Receiving_DropType_2020_0817.csv\")\n",
    "dropType = np.unique(receivingDrop['DropType_descr'])\n",
    "\n",
    "for i in dropType:\n",
    "\n",
    "    a = receivingDrop[receivingDrop['DropType_descr'] == i][['playerName','FP/routes']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/routes' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'] , how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b39001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd4984d3",
   "metadata": {},
   "source": [
    "<h5> Load Coverage Types <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "id": "a22916ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingCoverage = pd.read_csv(\"Split/Receiving_CoverageType_0817.csv\")\n",
    "receivingCoverage = pd.read_csv(\"Split/Receiving_CoverageType_2020_0817.csv\")\n",
    "coverageType = np.unique(receivingCoverage['CoverageType_descr'])\n",
    "\n",
    "for i in coverageType:\n",
    "\n",
    "    a = receivingCoverage[receivingCoverage['CoverageType_descr'] == i][['playerName','FP/routes']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/routes' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'] , how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a49272d",
   "metadata": {},
   "source": [
    "<h5> Load Defense<h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "758e7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingRoute_def = pd.read_csv(\"Split/Receiving_RouteType_def_0817.csv\")\n",
    "receivingRoute_def = pd.read_csv(\"Split/Receiving_RouteType_def_2020_0817.csv\")\n",
    "receivingRoute_def['route'] = receivingRoute_def['route'].astype(int)\n",
    "targetType = np.unique(receivingRoute_def['route'])\n",
    "\n",
    "for i in targetType:\n",
    "    a = receivingRoute_def[receivingRoute_def['route'] == i][['nickName','FP/routes']].reset_index(drop = True)\n",
    "    split = str(i) + \"_def\"\n",
    "    a = a.rename(columns={'FP/routes' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "id": "d2199b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingDrop_def = pd.read_csv(\"Split/Receiving_DropType_def_0817.csv\")\n",
    "receivingDrop_def = pd.read_csv(\"Split/Receiving_DropType_def_2020_0817.csv\")\n",
    "receivingDrop_def = receivingDrop_def.rename(columns = {'Team' : 'nickName'})\n",
    "dropType = np.unique(receivingDrop_def['DropType_descr'])\n",
    "\n",
    "\n",
    "for i in dropType:\n",
    "    a = receivingDrop_def[receivingDrop_def['DropType_descr'] == i][['nickName','FP/routes']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/routes' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "a2b0c31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#receivingCoverage_def = pd.read_csv(\"Split/Receiving_CoverageType_def_0817.csv\")\n",
    "receivingCoverage_def = pd.read_csv(\"Split/Receiving_CoverageType_def_2020_0817.csv\")\n",
    "coverageType = np.unique(receivingCoverage_def['CoverageType_descr'])\n",
    "\n",
    "\n",
    "for i in coverageType:\n",
    "    a = receivingCoverage_def[receivingCoverage_def['CoverageType_descr'] == i][['nickName','FP/routes']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/routes' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "ced96b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with position\n",
    "roster = pd.read_csv(\"roster.csv\", index_col = False)\n",
    "\n",
    "group = pd.merge(group, roster[['playerId', 'positionCategory']], left_on = ['playerId'],  #2\n",
    "                          right_on=['playerId'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "id": "48bd986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = group[(group['positionCategory'] == 'WR') | (group['positionCategory'] == 'TE')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000dcea1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f79dfa5",
   "metadata": {},
   "source": [
    "<h3> Train-Test split (same as passing)<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "697e9d32",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'standardize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-546e659b6342>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'standardize' is not defined"
     ]
    }
   ],
   "source": [
    "groupSplit = group.copy()\n",
    "\n",
    "train, test = train_test_split(groupSplit, test_size=0.2)\n",
    "\n",
    "trainNum = train.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "testNum = test.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "\n",
    "X_train = trainNum.drop(['FP_total'], axis = 1)\n",
    "y_train = trainNum['FP_total']\n",
    "X_test = testNum.drop(['FP_total'], axis = 1)\n",
    "y_test = testNum['FP_total']\n",
    "\n",
    "for i in X_train.columns:\n",
    "    X_train[i] = standardize(X_train[i])\n",
    "    \n",
    "for i in X_test.columns:    \n",
    "    X_test[i] = standardize(X_test[i])\n",
    "    \n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Convert to array for neural network\n",
    "X_train_array = np.asarray(X_train).astype('float32')\n",
    "X_test_array = np.asarray(X_test).astype('float32')\n",
    "\n",
    "y_train_array = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_array = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "# Neural network\n",
    "comparison_dict ={'model':[],'params': [],'score': []}\n",
    "params={'hidden_layer_sizes': [(20,5), (25,10)], \n",
    "        'activation': [ 'logistic', 'tanh', 'relu'], \n",
    "        'solver': ['sgd', 'adam'], \n",
    "        'alpha': [2, 10, 20]} \n",
    "# 'alpha': np.logspace(2,20)\n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha )\n",
    "                model = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                      activation = activation, solver = solver, alpha = alpha, random_state = 1)\n",
    "                model.fit(X_train_array, y_train_array)\n",
    "\n",
    "                y_test_pred = model.predict(X_test_array)\n",
    "                MSE = mean_squared_error(y_test_pred , y_test_array)\n",
    "                \n",
    "                model_score = math.sqrt(MSE)\n",
    "                comparison_dict['model'].append('neural_network_classifier')\n",
    "                comparison_dict['params'].append(model_params)\n",
    "                comparison_dict['score'].append(model_score)\n",
    "                \n",
    "dfMLResults = pd.DataFrame({'Model': comparison_dict.get('model') ,\n",
    "              'Param': comparison_dict.get('params') ,\n",
    "              'Score': comparison_dict.get('score')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e9475ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidate\n",
    "# ((20, 5), relu, adam, 20)\n",
    "\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes = (20, 5),\n",
    "                                      activation = 'relu', solver = 'adam', alpha = 20, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "7b31a4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['FP_total_pred'] = y_test_pred\n",
    "test_FP = test[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName',\n",
    "       'FP_total', 'FP_total_pred']].reset_index(drop = True)\n",
    "test_FP = test_FP.sort_values(by=['FP_total_pred'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "b45b50f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP.to_csv(\"NN_Data/Pred/ReceivingPred_081122.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8cf5aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1e4e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e468106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e672097b",
   "metadata": {},
   "source": [
    "<h2> 3. Rushing <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "id": "79ce5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "rushing = pd.read_csv(\"NN_Data/Defense/rushing_pbp_OPP_081022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "a9d4adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = rushing.groupby(by=['team',\"gameId\", \"playerId\",\"playerName\", 'oppTeamId','nickName']).sum()\n",
    "\n",
    "group.reset_index(inplace=True)\n",
    "group = group[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName','FP_total']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "7e50c9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blocking\n",
    "#rushingBlocking = pd.read_csv(\"Split/Rushing_BlockingScheme_0817.csv\")\n",
    "rushingBlocking = pd.read_csv(\"Split/Rushing_BlockingScheme_2020_0817.csv\")\n",
    "blockingType = np.unique(rushingBlocking['blockingSchemeType_descr'])\n",
    "\n",
    "for i in blockingType:\n",
    "\n",
    "    a = rushingBlocking[rushingBlocking['blockingSchemeType_descr'] == i][['playerName','FP/Touch']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/Touch' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'] , how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "id": "f5209450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction\n",
    "#rushingDirection = pd.read_csv(\"Split/Rushing_direction_0817.csv\")\n",
    "rushingDirection = pd.read_csv(\"Split/Rushing_direction_2020_0817.csv\")\n",
    "\n",
    "directionType = np.unique(rushingDirection['RunDirection_descr'])\n",
    "\n",
    "for i in directionType:\n",
    "\n",
    "    a = rushingDirection[rushingDirection['RunDirection_descr'] == i][['playerName','FP/Touch']].reset_index(drop = True)\n",
    "    a = a.rename(columns={'FP/Touch' : i})\n",
    "    group = pd.merge(group, a, left_on = ['playerName'], right_on=['playerName'] , how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86150bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "04d80020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense - blocking\n",
    "#rushingBlocking_def = pd.read_csv(\"Split/Rushing_Blocking_def_0817.csv\")\n",
    "rushingBlocking_def = pd.read_csv(\"Split/Rushing_Blocking_def_2020_0817.csv\")\n",
    "\n",
    "blockingType = np.unique(rushingBlocking_def['blockingSchemeType_descr'])\n",
    "\n",
    "for i in blockingType:\n",
    "    a = rushingBlocking_def[rushingBlocking_def['blockingSchemeType_descr'] == i][['nickName','FP/Touch']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/Touch' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "da315568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defense - direction\n",
    "#rushingDirection_def = pd.read_csv(\"Split/Rushing_Direction_def_0817.csv\")\n",
    "rushingDirection_def = pd.read_csv(\"Split/Rushing_Direction_def_2020_0817.csv\")\n",
    "\n",
    "direction = np.unique(rushingDirection_def['RunDirection_descr'])\n",
    "\n",
    "for i in direction:\n",
    "    a = rushingDirection_def[rushingDirection_def['RunDirection_descr'] == i][['nickName','FP/Touch']].reset_index(drop = True)\n",
    "    split = i + \"_def\"\n",
    "    a = a.rename(columns={'FP/Touch' : split})\n",
    "    group = pd.merge(group, a, left_on = ['nickName'], right_on=['nickName'], how = 'left')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "51890b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with position\n",
    "roster = pd.read_csv(\"roster.csv\", index_col = False)\n",
    "\n",
    "group = pd.merge(group, roster[['playerId', 'positionCategory']], left_on = ['playerId'],  #2\n",
    "                          right_on=['playerId'], how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "id": "6329c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "group = group[(group['positionCategory'] == 'RB')].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cedc877",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca7a1e94",
   "metadata": {},
   "source": [
    "<h5> Split and train (same as above) <h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "be141149",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupSplit = group.copy()\n",
    "\n",
    "train, test = train_test_split(groupSplit, test_size=0.2)\n",
    "\n",
    "trainNum = train.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "testNum = test.drop(columns = ['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName'])\n",
    "\n",
    "X_train = trainNum.drop(['FP_total'], axis = 1)\n",
    "y_train = trainNum['FP_total']\n",
    "X_test = testNum.drop(['FP_total'], axis = 1)\n",
    "y_test = testNum['FP_total']\n",
    "\n",
    "for i in X_train.columns:\n",
    "    X_train[i] = standardize(X_train[i])\n",
    "    \n",
    "for i in X_test.columns:    \n",
    "    X_test[i] = standardize(X_test[i])\n",
    "    \n",
    "X_train = X_train.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Convert to array for neural network\n",
    "X_train_array = np.asarray(X_train).astype('float32')\n",
    "X_test_array = np.asarray(X_test).astype('float32')\n",
    "\n",
    "y_train_array = np.asarray(y_train).astype('float32').reshape((-1,1))\n",
    "y_test_array = np.asarray(y_test).astype('float32').reshape((-1,1))\n",
    "\n",
    "# Neural network\n",
    "comparison_dict ={'model':[],'params': [],'score': []}\n",
    "params={'hidden_layer_sizes': [(20,5), (25,10)], \n",
    "        'activation': [ 'logistic', 'tanh', 'relu'], \n",
    "        'solver': ['sgd', 'adam'], \n",
    "        'alpha': [2, 10, 20]} \n",
    "# 'alpha': np.logspace(2,20)\n",
    "\n",
    "for hidden_layer_sizes in params['hidden_layer_sizes']:\n",
    "    for activation in params['activation']:\n",
    "        for solver in params['solver']:\n",
    "            for alpha in params['alpha']:\n",
    "                model_params = (hidden_layer_sizes, activation, solver, alpha )\n",
    "                model = MLPRegressor(hidden_layer_sizes = hidden_layer_sizes,\n",
    "                                      activation = activation, solver = solver, alpha = alpha, random_state = 1)\n",
    "                model.fit(X_train_array, y_train_array)\n",
    "\n",
    "                y_test_pred = model.predict(X_test_array)\n",
    "                MSE = mean_squared_error(y_test_pred , y_test_array)\n",
    "                \n",
    "                model_score = math.sqrt(MSE)\n",
    "                comparison_dict['model'].append('neural_network_classifier')\n",
    "                comparison_dict['params'].append(model_params)\n",
    "                comparison_dict['score'].append(model_score)\n",
    "                \n",
    "dfMLResults = pd.DataFrame({'Model': comparison_dict.get('model') ,\n",
    "              'Param': comparison_dict.get('params') ,\n",
    "              'Score': comparison_dict.get('score')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "baeca449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Candidates\n",
    "#((25, 10), relu, adam, 20)\n",
    "\n",
    "model = MLPRegressor(hidden_layer_sizes = (25, 10),\n",
    "                                      activation = 'relu', solver = 'adam', alpha = 20, random_state = 42)\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "45b39b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['FP_total_pred'] = y_test_pred\n",
    "test_FP = test[['team', 'gameId', 'playerId', 'playerName', 'oppTeamId', 'nickName',\n",
    "       'FP_total', 'FP_total_pred']].reset_index(drop = True)\n",
    "test_FP = test_FP.sort_values(by=['FP_total_pred'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "b3669791",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_FP.to_csv(\"NN_Data/Pred/RushingPred_081122.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aefc87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe82d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd62b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
